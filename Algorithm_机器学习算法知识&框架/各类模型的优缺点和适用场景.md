## 各类模型的优缺点和适用场景

### 树模型为何不适合处理高维稀疏特征？

reference：https://blog.csdn.net/weixin_42944192/article/details/101515510

现在模型普遍带有正则项，但是线性模型如lr是对权重的惩罚，w一旦过大，惩罚增大，压缩w的值，使其不至于过大；而树模型的惩罚项是对叶子权重和叶子结点、树的深度的惩罚，在下例的情况下只需要一个节点可以完美区分，惩罚项小。

举例：假设有1w 个样本， y类别0和1，100维特征，其中10个样本都是类别1，而特征 f1的值为0，1，且刚好这10个样本的 f1特征值都为1，其余9990样本都为0(在高维稀疏的情况下这种情况很常见)，我们都知道这种情况在树模型的时候，很容易优化出含一个使用 f1为分裂节点的树直接将数据划分的很好，但是当测试的时候，却会发现效果很差，因为这个特征只是刚好偶然间跟 y拟合到了这个规律，这也是我们常说的过拟合。但是当时我还是不太懂为什么线性模型就能对这种 case 处理的好？照理说 线性模型在优化之后不也会产生这样一个式子：y = W1*f1 + Wi*fi+….，其中 W1特别大以拟合这十个样本吗，因为反正 f1的值只有0和1，W1过大对其他9990样本不会有任何影响。