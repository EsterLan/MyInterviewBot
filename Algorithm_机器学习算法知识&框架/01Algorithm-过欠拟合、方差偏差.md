## AlgorithmEvaluation-过/欠拟合、方差/偏差

Reference：

https://www.jianshu.com/p/f2489ccc14b4

### 过拟合与方差

- 过拟合：	模型对训练数据呈现过当的情况，模型泛化能力差；高方差

- 高方差： 描述就是模型针对不同的样本的预测结果会产生剧烈变化。

### 过拟合解决方法

1. 交叉检验，通过交叉检验得到较优的模型参数;
2. 特征选择，减少特征数或使用较少的特征组合，对于按区间离散化的特征，增大划分的区间;
3. 正则化，常用的有 L1、L2 正则。而且 L1正则还可以自动进行特征选择;
4. 增加训练数据可以有限的避免过拟合;
5. Bagging ,将多个弱学习器Bagging 一下效果会好很多，比如随机森林等.
6. 降低模型复杂度：在数据较少时，降低模型复杂度是比较有效的方法，适当的降低模型复杂度可以降低模型对噪声的拟合度。神经网络中可以减少网络层数，减少神经元个数，dropout；决策树可以控制树的深度，剪枝等。

另DNN中的方法：

- early stop
- ensemble
- dropout
- regularization

### 欠拟合与高偏差

欠拟合：模型对训练数据拟合程度不够

高偏差：描述就是模型预测时预测的结果期望和真实结果相差比较大

### 减少欠拟合

1. 增加新特征，可以考虑加入进特征组合、高次特征，来增大假设空间;
2. 增加模型复杂度；尝试非线性模型，比如核SVM 、决策树、DNN等模型;
3. 如果有正则项可以小减正则项参数 ![\lambda](https://math.jianshu.com/math?formula=%5Clambda);
4. Boosting ,Boosting 往往会有较小的 Bias，比如 Gradient Boosting 等.



